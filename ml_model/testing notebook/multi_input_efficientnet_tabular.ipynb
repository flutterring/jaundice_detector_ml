{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773fc9bd",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.utils import class_weight\n",
    "from pathlib import Path\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b67c1a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Ensure utils is in path\n",
    "current_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "from utils.preprocessing import create_efficientnet_processor, SimpleTabularProcessor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1901d10b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# === Configuration (Embedded) ===\n",
    "CSV_PATH = \"../jaundice_dataset/chd_jaundice_published_2.csv\"\n",
    "IMAGES_DIR = Path(\"D:/NU_Courses/semester_6/MI/NeoJaundice/images\") # Absolute path\n",
    "MODEL_PATH_HEAD_ONLY = \"../best_efficientnet_tabular_head_only.keras\"\n",
    "MODEL_PATH_FINE_TUNED = \"../best_efficientnet_tabular_fine_tuned.keras\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0096c265",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Image Config\n",
    "IMG_SIZE_EFFICIENTNET = (224, 224)\n",
    "USE_CALIBRATION = True\n",
    "USE_AUGMENTATION = True # For fine-tuning phase of image branch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92445b4f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Tabular Config\n",
    "CATEGORICAL_COLS = ['gender'] \n",
    "NUMERICAL_COLS = ['gestational_age', 'age(day)', 'weight', 'blood(mg/dL)']\n",
    "TARGET_COL = 'jaundiced'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f56039",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Training Hyperparameters\n",
    "BATCH_SIZE = 32 \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d1170c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Stage 1: Head Training for Image Branch\n",
    "EPOCHS_HEAD = 10\n",
    "LEARNING_RATE_HEAD = 1e-3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a708820",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Stage 2: Fine-tuning for Image Branch + Combined Training\n",
    "EPOCHS_FINETUNE = 20\n",
    "LEARNING_RATE_FINETUNE = 5e-5 # For EfficientNet fine-tuning\n",
    "LEARNING_RATE_COMBINED = 1e-4 # For the combined model after image branch is fine-tuned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d673abaa",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "class MultiInputEfficientNetTabularDetector:\n",
    "    def __init__(self):\n",
    "        self.image_processor = create_efficientnet_processor(use_calibration=USE_CALIBRATION, use_augmentation=USE_AUGMENTATION)\n",
    "        self.tabular_processor = SimpleTabularProcessor()\n",
    "        self.model = None\n",
    "        self.tabular_input_shape = None\n",
    "\n",
    "    def _build_model(self, learning_rate, trainable_base_layers=0):\n",
    "        if self.tabular_input_shape is None:\n",
    "            raise ValueError(\"Tabular input shape must be set before building model.\")\n",
    "\n",
    "        # Image Branch (EfficientNetB0)\n",
    "        image_input = layers.Input(shape=(IMG_SIZE_EFFICIENTNET[0], IMG_SIZE_EFFICIENTNET[1], 3), name='image_input')\n",
    "        base_model = EfficientNetB0(\n",
    "            include_top=False, \n",
    "            weights='imagenet', \n",
    "            input_shape=(IMG_SIZE_EFFICIENTNET[0], IMG_SIZE_EFFICIENTNET[1], 3)\n",
    "        )\n",
    "        if trainable_base_layers == 0:\n",
    "            base_model.trainable = False\n",
    "        elif trainable_base_layers > 0:\n",
    "            base_model.trainable = True\n",
    "            for layer in base_model.layers[:-trainable_base_layers]:\n",
    "                layer.trainable = False\n",
    "        else: # Unfreeze all\n",
    "             base_model.trainable = True\n",
    "        \n",
    "        x_img = base_model(image_input, training=(False if trainable_base_layers == 0 else True))\n",
    "        x_img = layers.GlobalAveragePooling2D(name='image_features')(x_img)\n",
    "        \n",
    "        # Tabular Branch (MLP)\n",
    "        tabular_input = layers.Input(shape=(self.tabular_input_shape,), name='tabular_input')\n",
    "        x_tab = layers.Dense(64, activation='relu')(tabular_input)\n",
    "        x_tab = layers.BatchNormalization()(x_tab)\n",
    "        x_tab = layers.Dropout(0.3)(x_tab)\n",
    "        x_tab = layers.Dense(32, activation='relu', name='tabular_features')(x_tab)\n",
    "\n",
    "        # Concatenate features\n",
    "        concatenated = layers.concatenate([x_img, x_tab], name='concatenated_features')\n",
    "        \n",
    "        # Combined Classification Head\n",
    "        x = layers.Dropout(0.3)(concatenated)\n",
    "        x = layers.Dense(64, activation='relu')(x) # Slightly larger head\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Dropout(0.3)(x)\n",
    "        output = layers.Dense(1, activation='sigmoid', name='output')(x)\n",
    "        \n",
    "        model = keras.Model(inputs=[image_input, tabular_input], outputs=output)\n",
    "        model.compile(\n",
    "            optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "            loss='binary_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        return model\n",
    "\n",
    "    def load_and_preprocess_data(self, csv_path, images_dir):\n",
    "        df = pd.read_csv(csv_path)\n",
    "        df.columns = df.columns.str.strip()\n",
    "        all_tabular_cols = CATEGORICAL_COLS + NUMERICAL_COLS\n",
    "        # Basic validation\n",
    "        if not all(col in df.columns for col in all_tabular_cols + [TARGET_COL, 'image_idx']):\n",
    "            raise ValueError(\"Missing one or more required columns in CSV for multi-input EfficientNet.\")\n",
    "\n",
    "        images_processed, tabular_processed, labels = [], [], []\n",
    "        X_tabular_raw_full = df[all_tabular_cols]\n",
    "        self.tabular_processor.fit(X_tabular_raw_full, CATEGORICAL_COLS, NUMERICAL_COLS)\n",
    "        self.tabular_input_shape = self.tabular_processor.transform(X_tabular_raw_full.iloc[[0]]).shape[1]\n",
    "        print(f\"üõ†Ô∏è Tabular processor fitted. Expected tabular input shape: ({self.tabular_input_shape},)\")\n",
    "\n",
    "        for idx, row in df.iterrows():\n",
    "            image_path = images_dir / row['image_idx']\n",
    "            if image_path.exists():\n",
    "                image = self.image_processor.process_image(image_path, apply_augmentation=False)\n",
    "                images_processed.append(image)\n",
    "                tabular_data = self.tabular_processor.transform(pd.DataFrame([row[all_tabular_cols]]))\n",
    "                tabular_processed.append(tabular_data.flatten())\n",
    "                labels.append(row[TARGET_COL])\n",
    "        \n",
    "        if not images_processed: raise ValueError(\"No images processed.\")\n",
    "        print(f\"‚úÖ Dataset loaded. Images: {len(images_processed)}, Tabular: {len(tabular_processed)}, Labels: {len(labels)}\")\n",
    "        return [np.array(images_processed), np.array(tabular_processed)], np.array(labels)\n",
    "\n",
    "    def _train_phase(\n",
    "        self, X_train_inputs, y_train, X_val_inputs, y_val, \n",
    "        epochs, learning_rate, model_save_path,\n",
    "        initial_weights_path=None, trainable_base_layers=0,\n",
    "        use_augmentation_for_phase=False\n",
    "    ):\n",
    "        self.model = self._build_model(learning_rate=learning_rate, trainable_base_layers=trainable_base_layers)\n",
    "        if initial_weights_path and Path(initial_weights_path).exists():\n",
    "            print(f\"üíæ Loading initial weights from: {initial_weights_path}\")\n",
    "            self.model.load_weights(initial_weights_path)\n",
    "        \n",
    "        class_weights_val = class_weight.compute_class_weight(\n",
    "            class_weight='balanced', classes=np.unique(y_train), y=y_train\n",
    "        )\n",
    "        class_weights_dict = dict(enumerate(class_weights_val))\n",
    "        callbacks = [\n",
    "            keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=8, restore_best_weights=True, min_delta=0.0005),\n",
    "            keras.callbacks.ReduceLROnPlateau(monitor='val_loss', patience=4, factor=0.2, min_lr=1e-7),\n",
    "            keras.callbacks.ModelCheckpoint(model_save_path, save_best_only=True, monitor='val_accuracy', verbose=1, mode='max')\n",
    "        ]\n",
    "\n",
    "        X_train_images, X_train_tabular = X_train_inputs[0], X_train_inputs[1]\n",
    "        X_train_feed, y_train_feed = [X_train_images, X_train_tabular], y_train\n",
    "\n",
    "        if use_augmentation_for_phase and self.image_processor.use_augmentation:\n",
    "            print(\"üìà Applying runtime data augmentation to image branch for this phase.\")\n",
    "            aug_imgs, aug_tabs, aug_labels = [], [], []\n",
    "            for i in range(len(X_train_images)):\n",
    "                aug_imgs.append(X_train_images[i]); aug_tabs.append(X_train_tabular[i]); aug_labels.append(y_train[i])\n",
    "                aug_img = self.image_processor.augmentation(tf.expand_dims(X_train_images[i],0), training=True)[0].numpy()\n",
    "                aug_imgs.append(aug_img); aug_tabs.append(X_train_tabular[i]); aug_labels.append(y_train[i])\n",
    "            X_train_feed = [np.array(aug_imgs), np.array(aug_tabs)]\n",
    "            y_train_feed = np.array(aug_labels)\n",
    "            print(f\"üìä Training set expanded: {len(X_train_images)} -> {len(y_train_feed)} instances\")\n",
    "\n",
    "        history = self.model.fit(\n",
    "            X_train_feed, y_train_feed, validation_data=(X_val_inputs, y_val),\n",
    "            epochs=epochs, batch_size=BATCH_SIZE, callbacks=callbacks,\n",
    "            class_weight=class_weights_dict, verbose=1\n",
    "        )\n",
    "        return history\n",
    "\n",
    "    def train_two_stages(self, X_train_inputs, y_train, X_val_inputs, y_val):\n",
    "        print(\"\\n--- Stage 1: Training Head Only (EfficientNet image branch frozen) ---\")\n",
    "        # During head-only, the EfficientNet base is frozen. Augmentation is off.\n",
    "        history_head = self._train_phase(\n",
    "            X_train_inputs, y_train, X_val_inputs, y_val,\n",
    "            epochs=EPOCHS_HEAD, learning_rate=LEARNING_RATE_HEAD,\n",
    "            model_save_path=MODEL_PATH_HEAD_ONLY,\n",
    "            trainable_base_layers=0, # EfficientNet Base frozen\n",
    "            use_augmentation_for_phase=False\n",
    "        )\n",
    "\n",
    "        print(\"\\n--- Stage 2: Fine-tuning (Unfreezing some EfficientNet layers, combined model) ---\")\n",
    "        # During fine-tuning, unfreeze some EfficientNet layers. Augmentation for image branch is on.\n",
    "        history_finetune = self._train_phase(\n",
    "            X_train_inputs, y_train, X_val_inputs, y_val,\n",
    "            epochs=EPOCHS_FINETUNE, learning_rate=LEARNING_RATE_FINETUNE, # Lower LR for fine-tuning\n",
    "            model_save_path=MODEL_PATH_FINE_TUNED,\n",
    "            initial_weights_path=MODEL_PATH_HEAD_ONLY,\n",
    "            trainable_base_layers=60, # Unfreeze last 60 layers of EfficientNet\n",
    "            use_augmentation_for_phase=USE_AUGMENTATION \n",
    "        )\n",
    "        if Path(MODEL_PATH_FINE_TUNED).exists():\n",
    "            self.model.load_weights(MODEL_PATH_FINE_TUNED)\n",
    "        return history_head, history_finetune\n",
    "\n",
    "    def evaluate_model(self, X_test_inputs, y_test, model_path_to_load=None):\n",
    "        # Logic to load the correct model state for evaluation\n",
    "        load_path = model_path_to_load if model_path_to_load else MODEL_PATH_FINE_TUNED\n",
    "        if Path(load_path).exists():\n",
    "            print(f\"üíæ Loading weights for evaluation from: {load_path}\")\n",
    "            # Rebuild with potentially different trainable_base_layers if loading head-only vs fine-tuned\n",
    "            # For simplicity, assume fine-tuned config (60 layers unfrozen) if not head_only explicitly\n",
    "            trainable_layers_on_load = 0 if load_path == MODEL_PATH_HEAD_ONLY else 60\n",
    "            if self.model is None or self.model.name != self._build_model(0.001, trainable_layers_on_load).name: # crude check\n",
    "                 self.model = self._build_model(learning_rate=LEARNING_RATE_FINETUNE, trainable_base_layers=trainable_layers_on_load)\n",
    "            self.model.load_weights(load_path)\n",
    "        else:\n",
    "            raise ValueError(f\"Model not trained or weights not found at {load_path}\")\n",
    "\n",
    "        print(\"üìä Evaluating Multi-Input EfficientNet+Tabular Model...\")\n",
    "        predictions = self.model.predict(X_test_inputs)\n",
    "        y_pred = (predictions > 0.5).astype(int).flatten()\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        print(f\"\\nüéØ Results (Model: {Path(load_path).name}):\")\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"Image Calib: {USE_CALIBRATION}, Image Aug (fine-tune): {USE_AUGMENTATION}\")\n",
    "        print(classification_report(y_test, y_pred, target_names=['No Jaundice', 'Jaundice']))\n",
    "        return accuracy\n",
    "\n",
    "    def predict_proba(self, X_processed_inputs):\n",
    "        if self.model is None: raise ValueError(\"Model not trained/loaded.\")\n",
    "        return self.model.predict(X_processed_inputs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37bb8bf",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def test_multi_input_efficientnet_tabular_model():\n",
    "    print(\"üß† Testing Multi-Input EfficientNet+Tabular Jaundice Detector\")\n",
    "    print(\"=\" * 70)\n",
    "    detector = MultiInputEfficientNetTabularDetector()\n",
    "    \n",
    "    [X_images, X_tabular], y = detector.load_and_preprocess_data(CSV_PATH, IMAGES_DIR)\n",
    "    indices = np.arange(len(y))\n",
    "    train_indices, temp_indices, y_train, y_temp = train_test_split(indices, y, test_size=0.3, random_state=42, stratify=y)\n",
    "    val_indices, test_indices, y_val, y_test = train_test_split(temp_indices, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
    "\n",
    "    X_train = [X_images[train_indices], X_tabular[train_indices]]\n",
    "    X_val = [X_images[val_indices], X_tabular[val_indices]]\n",
    "    X_test = [X_images[test_indices], X_tabular[test_indices]]\n",
    "\n",
    "    print(f\"\\nDataset Summary: Train: {len(y_train)}, Val: {len(y_val)}, Test: {len(y_test)}\")\n",
    "    print(f\"X_train shapes: Image - {X_train[0].shape}, Tabular - {X_train[1].shape}\")\n",
    "\n",
    "    detector.train_two_stages(X_train, y_train, X_val, y_val)\n",
    "    accuracy = detector.evaluate_model(X_test, y_test, model_path_to_load=MODEL_PATH_FINE_TUNED)\n",
    "    print(f\"\\nüèÜ Multi-Input EfficientNet+Tabular Final Accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "    # Optional: Evaluate head-only model too\n",
    "    # accuracy_head = detector.evaluate_model(X_test, y_test, model_path_to_load=MODEL_PATH_HEAD_ONLY)\n",
    "    # print(f\"\\nüèÜ Multi-Input EfficientNet+Tabular Head-Only Accuracy: {accuracy_head:.4f}\")\n",
    "    return detector, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26081fe5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    test_multi_input_efficientnet_tabular_model() "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
