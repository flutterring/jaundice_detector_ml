{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0873cc2a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.utils import class_weight\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65df1fe",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Ensure utils is in path\n",
    "current_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "from utils.preprocessing import create_cnn_processor, SimpleTabularProcessor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e729ca",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# === Configuration (Embedded) ===\n",
    "SCRIPT_DIR = Path(__file__).resolve().parent\n",
    "CSV_PATH = SCRIPT_DIR.parent / \"jaundice_dataset/chd_jaundice_published_2.csv\"\n",
    "IMAGES_DIR = Path(\"D:/CS Project/ML pro/NeoJaundice/NeoJaundice/images\") # Absolute path\n",
    "MODEL_PATH = SCRIPT_DIR.parent / \"best_cnn_tabular_model.keras\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfd3091",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Image Config\n",
    "IMG_SIZE_CNN = (128, 128)\n",
    "USE_CALIBRATION = True\n",
    "USE_AUGMENTATION = True # Augmentation for the image branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd18fbed",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Tabular Config (using features provided by user)\n",
    "CATEGORICAL_COLS = ['gender'] \n",
    "NUMERICAL_COLS = ['gestational_age', 'age(day)', 'weight', 'blood(mg/dL)']\n",
    "TARGET_COL = 'jaundiced'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdba761",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Training Hyperparameters\n",
    "EPOCHS = 30\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 0.0005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8ce621",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "class MultiInputCNNTabularDetector:\n",
    "    def __init__(self):\n",
    "        self.image_processor = create_cnn_processor(use_calibration=USE_CALIBRATION, use_augmentation=USE_AUGMENTATION)\n",
    "        self.tabular_processor = SimpleTabularProcessor()\n",
    "        self.model = None\n",
    "        self.tabular_input_shape = None\n",
    "\n",
    "    def _build_model(self):\n",
    "        if self.tabular_input_shape is None:\n",
    "            raise ValueError(\"Tabular input shape must be set by loading data before building model.\")\n",
    "\n",
    "        # Image Branch (CNN - adapted from SimpleCNNJaundiceDetector)\n",
    "        image_input = layers.Input(shape=(IMG_SIZE_CNN[0], IMG_SIZE_CNN[1], 3), name='image_input')\n",
    "        x_img = layers.Conv2D(16, 3, padding='same', activation='relu')(image_input)\n",
    "        x_img = layers.BatchNormalization()(x_img)\n",
    "        x_img = layers.MaxPooling2D()(x_img)\n",
    "        x_img = layers.Dropout(0.1)(x_img)\n",
    "        x_img = layers.Conv2D(32, 3, padding='same', activation='relu')(x_img)\n",
    "        x_img = layers.BatchNormalization()(x_img)\n",
    "        x_img = layers.MaxPooling2D()(x_img)\n",
    "        x_img = layers.Dropout(0.1)(x_img)\n",
    "        x_img = layers.Conv2D(64, 3, padding='same', activation='relu')(x_img)\n",
    "        x_img = layers.BatchNormalization()(x_img)\n",
    "        x_img = layers.MaxPooling2D()(x_img)\n",
    "        x_img = layers.Dropout(0.2)(x_img)\n",
    "        x_img = layers.Conv2D(128, 3, padding='same', activation='relu')(x_img)\n",
    "        x_img = layers.BatchNormalization()(x_img)\n",
    "        x_img = layers.MaxPooling2D()(x_img)\n",
    "        x_img = layers.Dropout(0.2)(x_img)\n",
    "        x_img = layers.GlobalAveragePooling2D(name='image_features')(x_img)\n",
    "        \n",
    "        # Tabular Branch (MLP - adapted from TabularJaundiceDetector)\n",
    "        tabular_input = layers.Input(shape=(self.tabular_input_shape,), name='tabular_input')\n",
    "        x_tab = layers.Dense(64, activation='relu')(tabular_input) # Simplified MLP for tabular\n",
    "        x_tab = layers.BatchNormalization()(x_tab)\n",
    "        x_tab = layers.Dropout(0.3)(x_tab)\n",
    "        x_tab = layers.Dense(32, activation='relu', name='tabular_features')(x_tab)\n",
    "\n",
    "        # Concatenate features\n",
    "        concatenated = layers.concatenate([x_img, x_tab], name='concatenated_features')\n",
    "        \n",
    "        # Combined Classification Head\n",
    "        x = layers.Dropout(0.4)(concatenated)\n",
    "        x = layers.Dense(32, activation='relu')(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Dropout(0.3)(x)\n",
    "        output = layers.Dense(1, activation='sigmoid', name='output')(x)\n",
    "        \n",
    "        model = keras.Model(inputs=[image_input, tabular_input], outputs=output)\n",
    "        model.compile(\n",
    "            optimizer=keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "            loss='binary_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        return model\n",
    "\n",
    "    def load_and_preprocess_data(self, csv_path, images_dir):\n",
    "        df = pd.read_csv(csv_path)\n",
    "        df.columns = df.columns.str.strip() # Clean column names\n",
    "\n",
    "        # Verify all defined columns exist in the DataFrame\n",
    "        all_tabular_cols = CATEGORICAL_COLS + NUMERICAL_COLS\n",
    "        missing_tabular = [col for col in all_tabular_cols if col not in df.columns]\n",
    "        if missing_tabular:\n",
    "            raise ValueError(f\"Missing tabular columns in CSV: {missing_tabular}. Available: {df.columns.tolist()}\")\n",
    "        if TARGET_COL not in df.columns:\n",
    "            raise ValueError(f\"Missing target column '{TARGET_COL}' in CSV. Available: {df.columns.tolist()}\")\n",
    "        if 'image_idx' not in df.columns:\n",
    "             raise ValueError(f\"Missing 'image_idx' column in CSV for image paths. Available: {df.columns.tolist()}\")\n",
    "\n",
    "        images_processed, tabular_processed, labels = [], [], []\n",
    "        print(f\"üîç Loading and preprocessing data for Multi-Input CNN+Tabular model...\")\n",
    "\n",
    "        # Fit tabular processor on the whole tabular dataset subset first\n",
    "        X_tabular_raw_full = df[all_tabular_cols]\n",
    "        self.tabular_processor.fit(X_tabular_raw_full, CATEGORICAL_COLS, NUMERICAL_COLS)\n",
    "        self.tabular_input_shape = self.tabular_processor.transform(X_tabular_raw_full.iloc[[0]], CATEGORICAL_COLS, NUMERICAL_COLS).shape[1] # Get shape from one sample\n",
    "        print(f\"üõ†Ô∏è Tabular processor fitted. Expected tabular input shape: ({self.tabular_input_shape},)\")\n",
    "\n",
    "        for idx, row in df.iterrows():\n",
    "            if idx % 500 == 0: print(f\"Processed {idx}/{len(df)} data points\")\n",
    "            image_path = images_dir / row['image_idx']\n",
    "            if image_path.exists():\n",
    "                # Process image (no augmentation at loading time)\n",
    "                image = self.image_processor.process_image(image_path, apply_augmentation=False)\n",
    "                images_processed.append(image)\n",
    "                \n",
    "                # Process tabular data for this row\n",
    "                tabular_row_raw = pd.DataFrame([row[all_tabular_cols]])\n",
    "                tabular_data = self.tabular_processor.transform(tabular_row_raw, CATEGORICAL_COLS, NUMERICAL_COLS)\n",
    "                tabular_processed.append(tabular_data.flatten()) # Flatten to 1D array\n",
    "                \n",
    "                labels.append(row[TARGET_COL])\n",
    "        \n",
    "        if not images_processed: # Check if any images were successfully processed\n",
    "            raise ValueError(\"No images were processed. Check image_idx column and image paths.\")\n",
    "            \n",
    "        print(f\"‚úÖ Dataset loaded. Images: {len(images_processed)}, Tabular rows: {len(tabular_processed)}, Labels: {len(labels)}\")\n",
    "        return [np.array(images_processed), np.array(tabular_processed)], np.array(labels)\n",
    "\n",
    "    def train_model(self, X_train, y_train, X_val, y_val):\n",
    "        if self.model is None:\n",
    "            self.model = self._build_model()\n",
    "\n",
    "        class_weights_val = class_weight.compute_class_weight(\n",
    "            class_weight='balanced', classes=np.unique(y_train), y=y_train\n",
    "        )\n",
    "        class_weights_dict = dict(enumerate(class_weights_val))\n",
    "\n",
    "        callbacks = [\n",
    "            keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True, min_delta=0.001),\n",
    "            keras.callbacks.ReduceLROnPlateau(monitor='val_loss', patience=5, factor=0.3, min_lr=1e-7),\n",
    "            keras.callbacks.ModelCheckpoint(MODEL_PATH, save_best_only=True, monitor='val_accuracy', verbose=1, mode='max')\n",
    "        ]\n",
    "\n",
    "        print(\"üß† Training Multi-Input CNN+Tabular Model...\")\n",
    "        \n",
    "        # Handle data augmentation for the image part if enabled\n",
    "        # X_train is a list: [images, tabular_data]\n",
    "        X_train_images = X_train[0]\n",
    "        X_train_tabular = X_train[1]\n",
    "\n",
    "        if self.image_processor.use_augmentation:\n",
    "            print(\"üìà Applying runtime data augmentation to image branch.\")\n",
    "            augmented_images_train, augmented_tabular_train, augmented_labels_train = [], [], []\n",
    "            for i in range(len(X_train_images)):\n",
    "                # Original sample\n",
    "                augmented_images_train.append(X_train_images[i])\n",
    "                augmented_tabular_train.append(X_train_tabular[i])\n",
    "                augmented_labels_train.append(y_train[i])\n",
    "                \n",
    "                # Augmented image sample\n",
    "                aug_img = self.image_processor.augmentation(tf.expand_dims(X_train_images[i], 0), training=True)[0].numpy()\n",
    "                augmented_images_train.append(aug_img)\n",
    "                augmented_tabular_train.append(X_train_tabular[i]) # Tabular data remains the same\n",
    "                augmented_labels_train.append(y_train[i])\n",
    "\n",
    "            X_train_feed = [np.array(augmented_images_train), np.array(augmented_tabular_train)]\n",
    "            y_train_feed = np.array(augmented_labels_train)\n",
    "            print(f\"üìä Training set expanded (due to image augmentation): {len(X_train_images)} original pairs -> {len(y_train_feed)} training instances\")\n",
    "        else:\n",
    "            X_train_feed = X_train\n",
    "            y_train_feed = y_train\n",
    "            \n",
    "        history = self.model.fit(\n",
    "            X_train_feed, y_train_feed,\n",
    "            validation_data=(X_val, y_val),\n",
    "            epochs=EPOCHS, batch_size=BATCH_SIZE, callbacks=callbacks,\n",
    "            class_weight=class_weights_dict, verbose=1\n",
    "        )\n",
    "        return history\n",
    "\n",
    "    def evaluate_model(self, X_test, y_test):\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"Model not trained or loaded.\")\n",
    "        print(\"üìä Evaluating Multi-Input CNN+Tabular Model...\")\n",
    "        predictions = self.model.predict(X_test)\n",
    "        y_pred = (predictions > 0.5).astype(int).flatten()\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        print(f\"\\nüéØ Multi-Input CNN+Tabular Model Results:\")\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"Using image calibration: {USE_CALIBRATION}\")\n",
    "        print(f\"Using image augmentation: {USE_AUGMENTATION}\")\n",
    "        print(\"\\nClassification Report:\")\n",
    "        print(classification_report(y_test, y_pred, target_names=['No Jaundice', 'Jaundice']))\n",
    "        return accuracy\n",
    "\n",
    "    def predict_proba(self, X_processed_inputs):\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"Model not trained or loaded. Please train or load weights first.\")\n",
    "        return self.model.predict(X_processed_inputs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4f4b5b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def test_multi_input_cnn_tabular_model():\n",
    "    print(\"üß† Testing Multi-Input CNN+Tabular Jaundice Detector\")\n",
    "    print(\"=\" * 70)\n",
    "    detector = MultiInputCNNTabularDetector()\n",
    "    \n",
    "    # Load data\n",
    "    # Returns [images_array, tabular_array], labels_array\n",
    "    [X_images, X_tabular], y = detector.load_and_preprocess_data(CSV_PATH, IMAGES_DIR)\n",
    "\n",
    "    # Train/Val/Test Split for multi-input\n",
    "    # Ensure consistent splitting for both input types\n",
    "    indices = np.arange(len(y))\n",
    "    train_indices, temp_indices, y_train, y_temp = train_test_split(\n",
    "        indices, y, test_size=0.3, random_state=42, stratify=y\n",
    "    )\n",
    "    val_indices, test_indices, y_val, y_test = train_test_split(\n",
    "        temp_indices, y_temp, test_size=0.5, random_state=42, stratify=y_temp\n",
    "    )\n",
    "\n",
    "    X_train = [X_images[train_indices], X_tabular[train_indices]]\n",
    "    X_val = [X_images[val_indices], X_tabular[val_indices]]\n",
    "    X_test = [X_images[test_indices], X_tabular[test_indices]]\n",
    "\n",
    "    print(f\"\\nDataset Summary:\")\n",
    "    print(f\"Train: {len(y_train)}, Val: {len(y_val)}, Test: {len(y_test)}\")\n",
    "    print(f\"Class distribution (train): {np.unique(y_train, return_counts=True)}\")\n",
    "    print(f\"X_train shapes: Image - {X_train[0].shape}, Tabular - {X_train[1].shape}\")\n",
    "\n",
    "    # Train model\n",
    "    detector.train_model(X_train, y_train, X_val, y_val)\n",
    "    \n",
    "    # Load best weights for evaluation\n",
    "    if Path(MODEL_PATH).exists():\n",
    "        detector.model.load_weights(MODEL_PATH)\n",
    "    else:\n",
    "        print(f\"Warning: Model file {MODEL_PATH} not found. Evaluation might use last epoch weights.\")\n",
    "\n",
    "    # Evaluate model\n",
    "    accuracy = detector.evaluate_model(X_test, y_test)\n",
    "    print(f\"\\nüèÜ Multi-Input CNN+Tabular Model Accuracy: {accuracy:.4f}\")\n",
    "    return detector, accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647a18d9",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    test_multi_input_cnn_tabular_model()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
