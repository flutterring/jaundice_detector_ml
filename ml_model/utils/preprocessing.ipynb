{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: malformed \\N character escape (2216216134.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[19], line 3\u001b[1;36m\u001b[0m\n\u001b[1;33m    df = pd.read_csv('D:\\NU_Courses\\semester_6\\MI\\jaundice_detector_ml\\ml_model\\jaundice_dataset\\chd_jaundice_published_2.csv')\u001b[0m\n\u001b[1;37m                     ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: malformed \\N character escape\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('NU_Courses\\semester_6\\MI\\jaundice_detector_ml\\ml_model\\jaundice_dataset\\chd_jaundice_published_2.csv')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>image_idx</th>\n",
       "      <th>gender</th>\n",
       "      <th>gestational_age</th>\n",
       "      <th>age(day)</th>\n",
       "      <th>weight</th>\n",
       "      <th>blood(mg/dL)</th>\n",
       "      <th>Treatment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0003-1.jpg</td>\n",
       "      <td>F</td>\n",
       "      <td>40</td>\n",
       "      <td>5.2</td>\n",
       "      <td>3280</td>\n",
       "      <td>3.9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0003-2.jpg</td>\n",
       "      <td>F</td>\n",
       "      <td>40</td>\n",
       "      <td>5.2</td>\n",
       "      <td>3280</td>\n",
       "      <td>3.9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0003-3.jpg</td>\n",
       "      <td>F</td>\n",
       "      <td>40</td>\n",
       "      <td>5.2</td>\n",
       "      <td>3280</td>\n",
       "      <td>3.9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35</td>\n",
       "      <td>0035-1.jpg</td>\n",
       "      <td>M</td>\n",
       "      <td>39</td>\n",
       "      <td>8.7</td>\n",
       "      <td>3760</td>\n",
       "      <td>12.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35</td>\n",
       "      <td>0035-2.jpg</td>\n",
       "      <td>M</td>\n",
       "      <td>39</td>\n",
       "      <td>8.7</td>\n",
       "      <td>3760</td>\n",
       "      <td>12.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   patient_id   image_idx gender  gestational_age  age(day)  weight  \\\n",
       "0           3  0003-1.jpg      F               40       5.2    3280   \n",
       "1           3  0003-2.jpg      F               40       5.2    3280   \n",
       "2           3  0003-3.jpg      F               40       5.2    3280   \n",
       "3          35  0035-1.jpg      M               39       8.7    3760   \n",
       "4          35  0035-2.jpg      M               39       8.7    3760   \n",
       "\n",
       "   blood(mg/dL)  Treatment  \n",
       "0           3.9          0  \n",
       "1           3.9          0  \n",
       "2           3.9          0  \n",
       "3          12.2          0  \n",
       "4          12.2          0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2235 entries, 0 to 2234\n",
      "Data columns (total 8 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   patient_id       2235 non-null   int64  \n",
      " 1   image_idx        2235 non-null   object \n",
      " 2   gender           2235 non-null   object \n",
      " 3   gestational_age  2235 non-null   int64  \n",
      " 4   age(day)         2229 non-null   float64\n",
      " 5   weight           2235 non-null   int64  \n",
      " 6   blood(mg/dL)     2235 non-null   float64\n",
      " 7   Treatment        2235 non-null   int64  \n",
      "dtypes: float64(2), int64(4), object(2)\n",
      "memory usage: 139.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>gestational_age</th>\n",
       "      <th>age(day)</th>\n",
       "      <th>weight</th>\n",
       "      <th>blood(mg/dL)</th>\n",
       "      <th>Treatment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2235.000000</td>\n",
       "      <td>2235.000000</td>\n",
       "      <td>2229.000000</td>\n",
       "      <td>2235.000000</td>\n",
       "      <td>2235.000000</td>\n",
       "      <td>2235.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>747.554362</td>\n",
       "      <td>38.293960</td>\n",
       "      <td>6.599192</td>\n",
       "      <td>3158.778523</td>\n",
       "      <td>11.206846</td>\n",
       "      <td>0.417450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>420.653073</td>\n",
       "      <td>1.807409</td>\n",
       "      <td>5.703538</td>\n",
       "      <td>529.903610</td>\n",
       "      <td>5.213196</td>\n",
       "      <td>0.493249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1690.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>356.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2800.000000</td>\n",
       "      <td>7.400000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>794.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3180.000000</td>\n",
       "      <td>11.800000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1139.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>3500.000000</td>\n",
       "      <td>15.100000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1351.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>5290.000000</td>\n",
       "      <td>25.700000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        patient_id  gestational_age     age(day)       weight  blood(mg/dL)  \\\n",
       "count  2235.000000      2235.000000  2229.000000  2235.000000   2235.000000   \n",
       "mean    747.554362        38.293960     6.599192  3158.778523     11.206846   \n",
       "std     420.653073         1.807409     5.703538   529.903610      5.213196   \n",
       "min       1.000000        30.000000     0.100000  1690.000000      0.000000   \n",
       "25%     356.000000        37.000000     2.500000  2800.000000      7.400000   \n",
       "50%     794.000000        39.000000     5.000000  3180.000000     11.800000   \n",
       "75%    1139.000000        40.000000     9.000000  3500.000000     15.100000   \n",
       "max    1351.000000        42.000000    34.000000  5290.000000     25.700000   \n",
       "\n",
       "         Treatment  \n",
       "count  2235.000000  \n",
       "mean      0.417450  \n",
       "std       0.493249  \n",
       "min       0.000000  \n",
       "25%       0.000000  \n",
       "50%       0.000000  \n",
       "75%       1.000000  \n",
       "max       1.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       False\n",
       "1       False\n",
       "2       False\n",
       "3       False\n",
       "4       False\n",
       "        ...  \n",
       "2230    False\n",
       "2231    False\n",
       "2232    False\n",
       "2233    False\n",
       "2234    False\n",
       "Length: 2235, dtype: bool"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "patient_id         0\n",
       "image_idx          0\n",
       "gender             0\n",
       "gestational_age    0\n",
       "age(day)           6\n",
       "weight             0\n",
       "blood(mg/dL)       0\n",
       "Treatment          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "patient_id         False\n",
       "image_idx          False\n",
       "gender             False\n",
       "gestational_age    False\n",
       "age(day)            True\n",
       "weight             False\n",
       "blood(mg/dL)       False\n",
       "Treatment          False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().any(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['patient_id', 'image_idx', 'gender', 'gestational_age', 'age(day)',\n",
       "       'weight', 'blood(mg/dL)', 'Treatment'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['gender', 'age(day)', 'weight'], axis=1, errors='ignore')\n",
    "df.to_csv('chd_jaundice_published_2.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Treatment\"] = df[\"Treatment\"].map({0: \"not_jaundiced\", 1: \"jaundiced\"})\n",
    "df.to_csv('chd_jaundice_published_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Final shape: (2235, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "localDatasetPath = \"images\"\n",
    "\n",
    "image_names = df['image_idx'].tolist()\n",
    "\n",
    "processed_images = []\n",
    "\n",
    "def preprocess_image_tf(image_id):\n",
    "    filename = f\"{image_id}\" \n",
    "    full_path = os.path.join(localDatasetPath, filename)\n",
    "\n",
    "    img = tf.io.read_file(full_path)\n",
    "    img = tf.image.decode_image(img, channels=3)\n",
    "    img = tf.image.resize(img, [224, 224])\n",
    "    img = tf.cast(img, tf.float32) / 255.0\n",
    "    return img\n",
    "\n",
    "for image_id in image_names:\n",
    "    try:\n",
    "        processed_img = preprocess_image_tf(image_id)\n",
    "        processed_images.append(processed_img.numpy())\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error processing {image_id}: {e}\")\n",
    "\n",
    "processed_images = np.array(processed_images)\n",
    "print(\"✅ Final shape:\", processed_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Shapes:\n",
      "Train: (1564, 224, 224, 3) (1564,)\n",
      "Validation: (335, 224, 224, 3) (335,)\n",
      "Test: (336, 224, 224, 3) (336,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "X = processed_images  \n",
    "y = df[\"Treatment\"].map({\"not_jaundiced\": 0, \"jaundiced\": 1}).values  \n",
    "\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.30, stratify=y, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.50, stratify=y_temp, random_state=42)\n",
    "\n",
    "print(\" Shapes:\")\n",
    "print(\"Train:\", X_train.shape, y_train.shape)\n",
    "print(\"Validation:\", X_val.shape, y_val.shape)\n",
    "print(\"Test:\", X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Your images are already preprocessed and split as X_train, X_val, X_test, y_train, y_val, y_test\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "val_ds = tf.data.Dataset.from_tensor_slices((X_val, y_val)).batch(32).prefetch(tf.data.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
      "16705208/16705208 [==============================] - 4s 0us/step\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Remove corrupted EfficientNetB0 weights if they exist\n",
    "keras_cache_dir = os.path.expanduser(\"~/.keras/models\")\n",
    "for fname in os.listdir(keras_cache_dir):\n",
    "    if \"efficientnetb0\" in fname.lower():\n",
    "        os.remove(os.path.join(keras_cache_dir, fname))\n",
    "\n",
    "base_model = EfficientNetB0(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))\n",
    "base_model.trainable = False  # Freeze for transfer learning\n",
    "\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(1, activation='sigmoid')  # Binary classification\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "49/49 [==============================] - 55s 1s/step - loss: 0.6890 - accuracy: 0.5659 - val_loss: 0.6796 - val_accuracy: 0.5821\n",
      "Epoch 2/10\n",
      "49/49 [==============================] - 47s 967ms/step - loss: 0.6883 - accuracy: 0.5678 - val_loss: 0.6796 - val_accuracy: 0.5821\n",
      "Epoch 3/10\n",
      "49/49 [==============================] - 46s 950ms/step - loss: 0.6840 - accuracy: 0.5710 - val_loss: 0.6796 - val_accuracy: 0.5821\n",
      "Epoch 4/10\n",
      "49/49 [==============================] - 46s 945ms/step - loss: 0.6868 - accuracy: 0.5684 - val_loss: 0.6795 - val_accuracy: 0.5821\n",
      "Epoch 5/10\n",
      "49/49 [==============================] - 46s 940ms/step - loss: 0.6859 - accuracy: 0.5780 - val_loss: 0.6795 - val_accuracy: 0.5821\n",
      "Epoch 6/10\n",
      "49/49 [==============================] - 46s 939ms/step - loss: 0.6855 - accuracy: 0.5793 - val_loss: 0.6795 - val_accuracy: 0.5821\n",
      "Epoch 7/10\n",
      "49/49 [==============================] - 46s 939ms/step - loss: 0.6851 - accuracy: 0.5697 - val_loss: 0.6795 - val_accuracy: 0.5821\n",
      "Epoch 8/10\n",
      "49/49 [==============================] - 47s 958ms/step - loss: 0.6849 - accuracy: 0.5735 - val_loss: 0.6795 - val_accuracy: 0.5821\n",
      "Epoch 9/10\n",
      "49/49 [==============================] - 47s 958ms/step - loss: 0.6883 - accuracy: 0.5799 - val_loss: 0.6795 - val_accuracy: 0.5821\n",
      "Epoch 10/10\n",
      "49/49 [==============================] - 47s 962ms/step - loss: 0.6886 - accuracy: 0.5754 - val_loss: 0.6794 - val_accuracy: 0.5821\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_ds, validation_data=val_ds, epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Unable to serialize [2.0896919 2.1128857 2.1081853] to JSON. Unrecognized type <class 'tensorflow.python.framework.ops.EagerTensor'>.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mefficientnet_jaundice_model.h5\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\pepob\\anaconda3\\envs\\tf310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\pepob\\anaconda3\\envs\\tf310\\lib\\json\\__init__.py:238\u001b[0m, in \u001b[0;36mdumps\u001b[1;34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONEncoder\n\u001b[0;32m    234\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    235\u001b[0m \u001b[43m    \u001b[49m\u001b[43mskipkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_ascii\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_ascii\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheck_circular\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_circular\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    237\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseparators\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseparators\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m--> 238\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\pepob\\anaconda3\\envs\\tf310\\lib\\json\\encoder.py:199\u001b[0m, in \u001b[0;36mJSONEncoder.encode\u001b[1;34m(self, o)\u001b[0m\n\u001b[0;32m    195\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m encode_basestring(o)\n\u001b[0;32m    196\u001b[0m \u001b[38;5;66;03m# This doesn't pass the iterator directly to ''.join() because the\u001b[39;00m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;66;03m# exceptions aren't as detailed.  The list call should be roughly\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;66;03m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[39;00m\n\u001b[1;32m--> 199\u001b[0m chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_one_shot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(chunks, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[0;32m    201\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(chunks)\n",
      "File \u001b[1;32mc:\\Users\\pepob\\anaconda3\\envs\\tf310\\lib\\json\\encoder.py:257\u001b[0m, in \u001b[0;36mJSONEncoder.iterencode\u001b[1;34m(self, o, _one_shot)\u001b[0m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    253\u001b[0m     _iterencode \u001b[38;5;241m=\u001b[39m _make_iterencode(\n\u001b[0;32m    254\u001b[0m         markers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault, _encoder, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindent, floatstr,\n\u001b[0;32m    255\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey_separator, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitem_separator, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msort_keys,\n\u001b[0;32m    256\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskipkeys, _one_shot)\n\u001b[1;32m--> 257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_iterencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: Unable to serialize [2.0896919 2.1128857 2.1081853] to JSON. Unrecognized type <class 'tensorflow.python.framework.ops.EagerTensor'>."
     ]
    }
   ],
   "source": [
    "# model.save(\"efficientnet_jaundice_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "49/49 [==============================] - 100s 2s/step - loss: 0.7077 - accuracy: 0.5000 - val_loss: 0.6825 - val_accuracy: 0.5821\n",
      "Epoch 2/5\n",
      "49/49 [==============================] - 94s 2s/step - loss: 0.6914 - accuracy: 0.5294 - val_loss: 0.6925 - val_accuracy: 0.5582\n",
      "Epoch 3/5\n",
      "49/49 [==============================] - 91s 2s/step - loss: 0.6870 - accuracy: 0.5480 - val_loss: 0.7039 - val_accuracy: 0.4179\n",
      "Epoch 4/5\n",
      "49/49 [==============================] - 86s 2s/step - loss: 0.6755 - accuracy: 0.5812 - val_loss: 0.7111 - val_accuracy: 0.4179\n",
      "Epoch 5/5\n",
      "49/49 [==============================] - 88s 2s/step - loss: 0.6692 - accuracy: 0.5959 - val_loss: 0.7314 - val_accuracy: 0.4209\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f564cd3c10>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.trainable = True\n",
    "\n",
    "# Optional: Freeze first few layers to avoid catastrophic forgetting\n",
    "for layer in base_model.layers[:100]:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(1e-5), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(train_ds, validation_data=val_ds, epochs=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
